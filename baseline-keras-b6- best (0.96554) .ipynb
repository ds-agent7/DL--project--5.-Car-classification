{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация изображений\n",
    "\n",
    "### Основная идея этого решения: взять предобученую на ImageNet сеть Xception и дообучить под нашу задачу. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: efficientnet in /Users/paulmatus/opt/anaconda3/lib/python3.8/site-packages (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications<=1.0.8,>=1.0.7 in /Users/paulmatus/opt/anaconda3/lib/python3.8/site-packages (from efficientnet) (1.0.8)\n",
      "Requirement already satisfied, skipping upgrade: scikit-image in /Users/paulmatus/opt/anaconda3/lib/python3.8/site-packages (from efficientnet) (0.16.2)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /Users/paulmatus/opt/anaconda3/lib/python3.8/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /Users/paulmatus/opt/anaconda3/lib/python3.8/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /Users/paulmatus/opt/anaconda3/lib/python3.8/site-packages (from scikit-image->efficientnet) (7.2.0)\n",
      "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /Users/paulmatus/opt/anaconda3/lib/python3.8/site-packages (from scikit-image->efficientnet) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /Users/paulmatus/opt/anaconda3/lib/python3.8/site-packages (from scikit-image->efficientnet) (2.4)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.0 in /Users/paulmatus/opt/anaconda3/lib/python3.8/site-packages (from scikit-image->efficientnet) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /Users/paulmatus/opt/anaconda3/lib/python3.8/site-packages (from scikit-image->efficientnet) (3.2.2)\n",
      "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /Users/paulmatus/opt/anaconda3/lib/python3.8/site-packages (from scikit-image->efficientnet) (2.9.0)\n",
      "Requirement already satisfied, skipping upgrade: six in /Users/paulmatus/opt/anaconda3/lib/python3.8/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /Users/paulmatus/opt/anaconda3/lib/python3.8/site-packages (from networkx>=2.0->scikit-image->efficientnet) (4.4.2)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/paulmatus/opt/anaconda3/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /Users/paulmatus/opt/anaconda3/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /Users/paulmatus/opt/anaconda3/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /Users/paulmatus/opt/anaconda3/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install - -upgrade efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import scipy.io\n",
    "import tarfile\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.models as M\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.callbacks as C\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras import optimizers\n",
    "import efficientnet.tfkeras as efn\n",
    "import zipfile\n",
    "\n",
    "from ImageDataAugmentor.image_data_augmentor import *\n",
    "import albumentations\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import PIL\n",
    "from PIL import ImageOps, ImageFilter\n",
    "# увеличим дефолтный размер графиков\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 5\n",
    "# графики в svg выглядят более четкими\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%matplotlib inline\n",
    "\n",
    "print(os.listdir(\"../input\"))\n",
    "print('Python       :', sys.version.split('\\n')[0])\n",
    "print('Numpy        :', np.__version__)\n",
    "print('Tensorflow   :', tf.__version__)\n",
    "print('Keras        :', tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Работаем с Tensorflow v2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Основные настройки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# В setup выносим основные настройки: так удобнее их перебирать в дальнейшем.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20  # эпох на обучение\n",
    "# уменьшаем batch если сеть большая, иначе не влезет в память на GPU  (Для модели B6 делаем 8, иначе в память не влезет )\n",
    "BATCH_SIZE = 8\n",
    "LR = 1e-4  # можно взять меньше\n",
    "VAL_SPLIT = 0.20  # сколько данных выделяем на тест от 15до 30%\n",
    "CLASS_NUM = 10  # количество классов в нашей задаче\n",
    "IMG_SIZE = 299  # какого размера подаем изображения в сеть\n",
    "IMG_CHANNELS = 3  # у RGB 3 канала\n",
    "input_shape = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n",
    "DATA_PATH = '../input/'\n",
    "PATH = \"../working/car/\"  # рабочая директория"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# Устаналиваем конкретное значение random seed для воспроизводимости\n",
    "# os.makedirs(PATH,exist_ok=False)\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "PYTHONHASHSEED = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA / Анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DATA_PATH+\"train.csv\")\n",
    "sample_submission = pd.read_csv(DATA_PATH+\"sample-submission.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.Category.value_counts()\n",
    "# распределение классов достаточно равномерное - это хорошо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Распаковываем картинки')\n",
    "# Will unzip the files so that you can see them..\n",
    "for data_zip in ['train.zip', 'test.zip']:\n",
    "    with zipfile.ZipFile(\"../input/\"+data_zip, \"r\") as z:\n",
    "        z.extractall(PATH)\n",
    "\n",
    "print(os.listdir(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "print('Пример картинок (random sample)')\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "random_image = train_df.sample(n=9)\n",
    "random_image_paths = random_image['Id'].values\n",
    "random_image_cat = random_image['Category'].values\n",
    "\n",
    "for index, path in enumerate(random_image_paths):\n",
    "    im = PIL.Image.open(PATH+f'train/{random_image_cat[index]}/{path}')\n",
    "    plt.subplot(3, 3, index+1)\n",
    "    plt.imshow(im)\n",
    "    plt.title('Class: '+str(random_image_cat[index]))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на примеры картинок и их размеры чтоб понимать как их лучше обработать и сжимать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = PIL.Image.open(PATH+'/train/0/100380.jpg')\n",
    "imgplot = plt.imshow(image)\n",
    "plt.show()\n",
    "image.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Аугментация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Аугментация данных важна, когда мы работаем с небольшим датасетом. Это как раз наш случай.\n",
    "# Прообуем 2 варианта аугментации\n",
    "# Вариант №1\n",
    "\n",
    "# train_datagen = ImageDataGenerator(\n",
    "# rescale=1. / 255,\n",
    "#  rotation_range = 6,\n",
    "# width_shift_range=0.1,\n",
    "# height_shift_range=0.2,\n",
    "# validation_split=VAL_SPLIT, # set validation split\n",
    "# horizontal_flip=False)\n",
    "\n",
    "#test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# Рекомендация Подключите более продвинутые библиотеки аугментации изображений (например: albumentations или imgaug, для них есть специальные \"обертки\" под Keras, например: https://github.com/mjkvaak/ImageDataAugmentor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вариант аугментации №2, более продвинутый ImageDataAugmentor на базе albumentations\n",
    "# его и будем использовать:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install git+https: // github.com/mjkvaak/ImageDataAugmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine,\n",
    "    IAASharpen, IAAEmboss, RandomContrast, RandomBrightness, Flip, OneOf, Compose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ImageDataAugmentor.image_data_augmentor import *\n",
    "import albumentations\n",
    "\n",
    "AUGMENTATIONS = albumentations.Compose([\n",
    "    albumentations.HorizontalFlip(p=0.5),\n",
    "    albumentations.Rotate(limit=45, interpolation=1, border_mode=4,\n",
    "                          value=None, mask_value=None, always_apply=False, p=0.5),\n",
    "    albumentations.OneOf([\n",
    "        albumentations.CenterCrop(height=250, width=200),\n",
    "        albumentations.CenterCrop(height=200, width=250),\n",
    "    ], p=0.5),\n",
    "    albumentations.OneOf([\n",
    "        albumentations.RandomBrightnessContrast(\n",
    "            brightness_limit=0.3, contrast_limit=0.3),\n",
    "        albumentations.RandomBrightnessContrast(\n",
    "            brightness_limit=0.1, contrast_limit=0.1)\n",
    "    ], p=0.5),\n",
    "    albumentations.GaussianBlur(p=0.05),\n",
    "    albumentations.HueSaturationValue(p=0.5),\n",
    "    albumentations.RGBShift(p=0.5),\n",
    "    albumentations.FancyPCA(alpha=0.1, always_apply=False, p=0.5),\n",
    "    albumentations.Resize(IMG_SIZE, IMG_SIZE)\n",
    "])\n",
    "\n",
    "train_datagen = ImageDataAugmentor(\n",
    "    rescale=1./255,\n",
    "    augment=AUGMENTATIONS,\n",
    "    validation_split=VAL_SPLIT,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataAugmentor(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Завернем наши данные в генератор:\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    PATH+'train/',      # директория где расположены папки с картинками\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True, seed=RANDOM_SEED,\n",
    "    subset='training')  # set as training data\n",
    "\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "    PATH+'train/',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True, seed=RANDOM_SEED,\n",
    "    subset='validation')  # set as validation data\n",
    "\n",
    "test_sub_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=sample_submission,\n",
    "    directory=PATH+'test_upload/',\n",
    "    x_col=\"Id\",\n",
    "    y_col=None,\n",
    "    shuffle=False,\n",
    "    class_mode=None,\n",
    "    seed=RANDOM_SEED,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Построение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Можно построить на базе предобученной сети Xception:\n",
    "# base_model = Xception(weights='imagenet', include_top=False, input_shape = input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Но мы будем использовать другую сеть, которая показыает лучше результаты \"EfficientNetB6\"\n",
    "import efficientnet.tfkeras as efn\n",
    "input_shape = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n",
    "base_model = efn.EfficientNetB6(\n",
    "    weights='imagenet',  # Подгружаем веса imagenet\n",
    "    include_top=False,\n",
    "    input_shape=input_shape\n",
    ")  # Выходной слой (голову) будем менять т.к. у нас други классы input_shape = input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Устанавливаем новую \"голову\" (head):\n",
    "model = M.Sequential()\n",
    "model.add(base_model)\n",
    "# объединяем все признаки в единый вектор\n",
    "model.add(L.GlobalAveragePooling2D(),)\n",
    "# Экспериментируем с архитектурой - добавляем  один (от 1 до 4 плотных) полносвязный слой, dropout и batch-нормализацию\n",
    "# elu ,leaky_ReLU, sigmoid, tanh - как альтернативные варианты\n",
    "model.add(L.Dense(256, activation='relu'))\n",
    "model.add(L.Dropout(0.20))\n",
    "model.add(L.BatchNormalization())\n",
    "model.add(L.Dense(128, activation='relu'))\n",
    "model.add(L.Dropout(0.30))\n",
    "model.add(L.BatchNormalization())\n",
    "#model.add(L.Dense(64, activation='relu'))\n",
    "#model.add(L.Dropout(0.35))\n",
    "#model.add(L.BatchNormalization())\n",
    "#model.add(L.Dense(64, activation='relu'))\n",
    "#model.add(L.Dropout(0.45))\n",
    "#model.add(L.BatchNormalization())\n",
    "model.add(L.Dense(CLASS_NUM, activation='softmax'))  # \"sigmoid\" как вариант\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "model.summary()\n",
    "# Рекомендация: Попробуйте добавить Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим ModelCheckpoint чтоб сохранять прогресс обучения модели и можно было потом подгрузить и дообучить модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('best_model.hdf5', monitor=[\n",
    "                             'val_accuracy'], verbose=1, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# Рекомендация 1. Добавьте другие функции из https://keras.io/callbacks/\n",
    "# Рекомендация 2. Используйте разные техники управления Learning Rate\n",
    "# https://towardsdatascience.com/finding-good-learning-rate-and-the-one-cycle-policy-7159fe1db5d6 (eng)\n",
    "# http://teleported.in/posts/cyclic-learning-rate/ (eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим технику EarlyStopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "callbacks_list = [checkpoint, earlystop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=len(test_generator),\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks_list\n",
    ")\n",
    "# Рекомендация: попробуйте применить transfer learning с fine-tuning - изучил, но не успел реализовать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраним итоговую сеть и подгрузим лучшую итерацию в обучении (best_model)\n",
    "model.save('../working/model_last.hdf5')\n",
    "model.load_weights('best_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "scores = model.evaluate_generator(\n",
    "    test_generator, steps=len(test_generator), verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В Итоге точность нашей модели составила 96.55%. \n",
    "Учитывая что классов 10 - это Очень хороший результат!     \n",
    "Посмотрим графики обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предсказание на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sub_generator.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sub_generator.reset()\n",
    "predictions = model.predict_generator(\n",
    "    test_sub_generator, steps=len(test_sub_generator), verbose=1)\n",
    "predictions = np.argmax(predictions, axis=-1)  # multiple categories\n",
    "label_map = (train_generator.class_indices)\n",
    "label_map = dict((v, k) for k, v in label_map.items())  # flip k,v\n",
    "predictions = [label_map[k] for k in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_with_dir = test_sub_generator.filenames\n",
    "submission = pd.DataFrame(\n",
    "    {'Id': filenames_with_dir, 'Category': predictions}, columns=['Id', 'Category'])\n",
    "submission['Id'] = submission['Id'].replace('test_upload/', '')\n",
    "submission.to_csv('submission.csv10', index=False)\n",
    "print('Save submit')\n",
    "\n",
    "# Рекомендация: попробуйте добавить Test Time Augmentation (TTA)  - не успел.\n",
    "# https://towardsdatascience.com/test-time-augmentation-tta-and-how-to-perform-it-with-keras-4ac19b67fb4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('/kaggle/working/submission14.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# Clean PATH\n",
    "import shutil\n",
    "shutil.rmtree(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Что можно было сделать, чтобы улучшить результат:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Примените transfer learning с fine-tuning\n",
    "* Подберите другие переменные (размер картинки, батч и т.д.)\n",
    "* Добавьте TTA (Test Time Augmentation)\n",
    "* Дополнительно*: Используйте разные техники управления Learning Rate (https://towardsdatascience.com/finding-good-learning-rate-and-the-one-cycle-policy-7159fe1db5d6 (eng) http://teleported.in/posts/cyclic-learning-rate/ (eng))\n",
    "* Дополнительно*: Добавьте более продвинутые библиотеки аугментации изображений (например, Albumentations )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# выводы:\n",
    "Построили вполне хорошую модель, от победителя отстали менее 1%, при этом система не такая нагруженная и быстрее в 4 раза.\n",
    "Занял 26 место из 97 на Kaggle.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
